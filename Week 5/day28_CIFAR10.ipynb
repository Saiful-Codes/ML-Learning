{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b11bc53",
   "metadata": {},
   "source": [
    "# Week 5_Day 5 : CIFAR-10 Tiny Model + GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5bf701",
   "metadata": {},
   "source": [
    "### CONCEPT 1: CIFAR-10 Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa606d",
   "metadata": {},
   "source": [
    "**What is CIFAR-10?**\n",
    "\n",
    "CIFAR-10 is a dataset of **60,000 color images** divided into **10 classes**:\n",
    "\n",
    "- airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "\n",
    "**Dataset Split**\n",
    "\n",
    "- **50,000** training images  \n",
    "- **10,000** test images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5a1bc",
   "metadata": {},
   "source": [
    "### CONCEPT 2: Image shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b710e",
   "metadata": {},
   "source": [
    "**In PyTorch, images usually look like this:**\n",
    "\n",
    "=> (C, H, W)\n",
    "\n",
    "- C = channels (RGB = 3)  \n",
    "- H = height  \n",
    "- W = width  \n",
    "\n",
    "**So a CIFAR-10 image is:**\n",
    "\n",
    "- (3, 32, 32)\n",
    "\n",
    "**A batch is:**\n",
    "\n",
    "- (batch_size, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a52d070",
   "metadata": {},
   "source": [
    "### HANDS-ON â€” Load CIFAR-10 and inspect shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea9d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb27bf",
   "metadata": {},
   "source": [
    "Step 1: Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cebb68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2470, 0.2435, 0.2616))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74541500",
   "metadata": {},
   "source": [
    "Step 2: Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad8bbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3242bb",
   "metadata": {},
   "source": [
    "Step 3: Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e57c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe8ee7",
   "metadata": {},
   "source": [
    "Step 4: Check One Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f048e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([64, 3, 32, 32])\n",
      "Labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029e610",
   "metadata": {},
   "source": [
    "### Defining a Tiny Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc35ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyFC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*32*32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "model = TinyFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c14832",
   "metadata": {},
   "source": [
    "### CONCEPT 3: GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37b19b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# move model to device\n",
    "model.to(device)\n",
    "\n",
    "# move every batch to device\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b5c63",
   "metadata": {},
   "source": [
    "### Training Loop & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9848157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train Loss: 1.6859 | Test Acc: 45.95%\n",
      "Epoch 2/2 | Train Loss: 1.4710 | Test Acc: 47.91%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def accuracy_on_loader(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = model(images)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    test_acc = accuracy_on_loader(model, test_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Test Acc: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce040910",
   "metadata": {},
   "source": [
    "### CPU vs GPU speed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debd8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU  -> Loss: 1.6866, Time: 7.53s\n",
      "GPU  -> Loss: 1.6789, Time: 9.82s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def time_one_epoch(on_device):\n",
    "    model = TinyFC().to(on_device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    start = time.time()\n",
    "    loss = train_one_epoch(model, train_loader, optimizer, criterion, on_device)\n",
    "    end = time.time()\n",
    "\n",
    "    return loss, end - start\n",
    "\n",
    "# CPU timing\n",
    "cpu_loss, cpu_time = time_one_epoch(torch.device(\"cpu\"))\n",
    "print(f\"CPU  -> Loss: {cpu_loss:.4f}, Time: {cpu_time:.2f}s\")\n",
    "\n",
    "# GPU timing (if available)\n",
    "if torch.cuda.is_available():\n",
    "    gpu_loss, gpu_time = time_one_epoch(torch.device(\"cuda\"))\n",
    "    print(f\"GPU  -> Loss: {gpu_loss:.4f}, Time: {gpu_time:.2f}s\")\n",
    "else:\n",
    "    print(\"No GPU available on this machine.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
